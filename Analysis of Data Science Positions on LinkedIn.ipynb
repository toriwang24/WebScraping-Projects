{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "206b954e",
   "metadata": {},
   "source": [
    "## This is an experimental notebook to conduct analysis on data scientist positions on Linkedin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91772ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236fcf89-48bf-4510-9fce-7474bf3001f5",
   "metadata": {},
   "source": [
    "## The following cell collects linkedin job data and creates a dataframe with 531 rows.\n",
    "\n",
    "Do not rerun!! The data has been collected to a csv file 'data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e08e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating loop to go through all pages\n",
    "job_list = []\n",
    "for page_num in range(1,100):\n",
    "    list_url = f\"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=Data%2BScientist&location=San%2BFrancisco%2BBay%2BArea&geoId=90000084&trk=public_jobs_jobs-search-bar_search-submit&start={page_num}\" \n",
    "    # Getting response request from list \n",
    "    response = requests.get(list_url)\n",
    "\n",
    "    list_data = response.text\n",
    "    list_soup = BeautifulSoup(list_data, 'html.parser')\n",
    "    page_jobs = list_soup.find_all(\"li\")\n",
    "    #10 jobs per page\n",
    "    #print(len(page_jobs))\n",
    "    \n",
    "    ## Get job ID's from each page\n",
    "    id_list = []\n",
    "\n",
    "    for job in page_jobs:\n",
    "        base_card_div = job.find(\"div\", {\"class\": \"base-card\"})\n",
    "        job_id = base_card_div.get(\"data-entity-urn\").split(\":\")[3]\n",
    "        id_list.append(job_id)\n",
    "        \n",
    "    # For every job with ID, get the information\n",
    "    for job_id in id_list:\n",
    "        job_url = f\"https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{job_id}\"\n",
    "        job_response = requests.get(job_url)\n",
    "        if(job_response.status_code == 200):\n",
    "            #print(job_response.status_code)\n",
    "            job_soup = BeautifulSoup(job_response.text, \"html.parser\")\n",
    "            job_post = {}\n",
    "            try:\n",
    "                job_post[\"company_name\"] = job_soup.find( \"a\", {\"class\": \"topcard__org-name-link topcard__flavor--black-link\"}).text.strip()\n",
    "            except: \n",
    "                job_post[\"company_name\"] = None\n",
    "            try:\n",
    "                job_post[\"job_title\"] = job_soup.find( \"h2\", {\"class\": \"top-card-layout__title font-sans text-lg papabear:text-xl font-bold leading-open text-color-text mb-0 topcard__title\"}).text.strip()\n",
    "            except: \n",
    "                job_post[\"job_title\"] = None\n",
    "            try:\n",
    "                job_post[\"job_description\"] = job_soup.find( \"div\", {\"class\":\"show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden\" }).text.strip()\n",
    "            except: \n",
    "                job_post[\"job_description\"] = None\n",
    "            try:\n",
    "                job_post[\"days_ago_posted\"] = job_soup.find( \"span\", {\"class\": \"posted-time-ago__text topcard__flavor--metadata\"}).text.strip()\n",
    "            except:\n",
    "                job_post[\"days_ago_posted\"] = None\n",
    "            try:\n",
    "                job_post[\"num_applicants\"] = job_soup.find( \"figcaption\", {\"class\": \"num-applicants__caption\"}).text.strip()\n",
    "            except:\n",
    "                job_post[\"num_applicants\"] = None\n",
    "            job_list.append(job_post)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65d638bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_description</th>\n",
       "      <th>days_ago_posted</th>\n",
       "      <th>num_applicants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Notion</td>\n",
       "      <td>Data Scientist, Product</td>\n",
       "      <td>About UsWe're on a mission to make it possible...</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netflix</td>\n",
       "      <td>Machine Learning Engineer Intern, Summer 2025</td>\n",
       "      <td>Netflix is one of the world's leading entertai...</td>\n",
       "      <td>1 month ago</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google</td>\n",
       "      <td>Data Scientist, Search Discovery, Research, Se...</td>\n",
       "      <td>Minimum qualifications:Master's degree in Stat...</td>\n",
       "      <td>3 weeks ago</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fractal</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data ScientistFractal Analytics is a strategic...</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fractal</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data ScientistFractal Analytics is a strategic...</td>\n",
       "      <td>6 days ago</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>SynergisticIT</td>\n",
       "      <td>: Entry Level Data Scientist</td>\n",
       "      <td>About UsSynergistic IT is a full-service staff...</td>\n",
       "      <td>4 months ago</td>\n",
       "      <td>Be among the first 25 applicants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>SoFi</td>\n",
       "      <td>Staff Data Scientist, Home Loans</td>\n",
       "      <td>Employee Applicant Privacy NoticeWho we are:Sh...</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>Meta</td>\n",
       "      <td>Data Scientist, Product Analytics</td>\n",
       "      <td>As a Data Scientist at Meta, you will shape th...</td>\n",
       "      <td>3 weeks ago</td>\n",
       "      <td>Be among the first 25 applicants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>Senior AI Scientist</td>\n",
       "      <td>LinkedIn is the world’s largest professional n...</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>dynamism vc</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>AI / Machine Learning Engineers with Full Stac...</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      company_name                                          job_title  \\\n",
       "0           Notion                            Data Scientist, Product   \n",
       "1          Netflix      Machine Learning Engineer Intern, Summer 2025   \n",
       "2           Google  Data Scientist, Search Discovery, Research, Se...   \n",
       "3          Fractal                                     Data Scientist   \n",
       "4          Fractal                                     Data Scientist   \n",
       "..             ...                                                ...   \n",
       "527  SynergisticIT                       : Entry Level Data Scientist   \n",
       "528           SoFi                   Staff Data Scientist, Home Loans   \n",
       "529           Meta                  Data Scientist, Product Analytics   \n",
       "530       LinkedIn                                Senior AI Scientist   \n",
       "531    dynamism vc                          Machine Learning Engineer   \n",
       "\n",
       "                                       job_description days_ago_posted  \\\n",
       "0    About UsWe're on a mission to make it possible...      1 week ago   \n",
       "1    Netflix is one of the world's leading entertai...     1 month ago   \n",
       "2    Minimum qualifications:Master's degree in Stat...     3 weeks ago   \n",
       "3    Data ScientistFractal Analytics is a strategic...      3 days ago   \n",
       "4    Data ScientistFractal Analytics is a strategic...      6 days ago   \n",
       "..                                                 ...             ...   \n",
       "527  About UsSynergistic IT is a full-service staff...    4 months ago   \n",
       "528  Employee Applicant Privacy NoticeWho we are:Sh...      2 days ago   \n",
       "529  As a Data Scientist at Meta, you will shape th...     3 weeks ago   \n",
       "530  LinkedIn is the world’s largest professional n...     2 weeks ago   \n",
       "531  AI / Machine Learning Engineers with Full Stac...     2 weeks ago   \n",
       "\n",
       "                       num_applicants  \n",
       "0                 Over 200 applicants  \n",
       "1                 Over 200 applicants  \n",
       "2                 Over 200 applicants  \n",
       "3                 Over 200 applicants  \n",
       "4                 Over 200 applicants  \n",
       "..                                ...  \n",
       "527  Be among the first 25 applicants  \n",
       "528                              None  \n",
       "529  Be among the first 25 applicants  \n",
       "530               Over 200 applicants  \n",
       "531               Over 200 applicants  \n",
       "\n",
       "[532 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df = pd.DataFrame(job_list)\n",
    "jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a96c7fe-2a05-4e3d-bce0-f157a671a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e1580b-05cf-496a-a603-7c3ba79d6165",
   "metadata": {},
   "source": [
    "## From here on we will use the data.csv file that we exported the data to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6853275-776c-448c-aca0-c98851b34396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/toriwang/Documents/GitHub/WebScraping-Projects'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c6e7476-2881-4ed2-af2c-894c53261e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/bin/python3.10\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac21b94e-eb98-49d4-af5e-d6fb081ea7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df = pd.read_csv('job_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52da9a72-7d31-448c-a0a6-b67772937832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(jobs_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcfd3203-1492-45b6-a924-04be927a82bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import ngrams\n",
    "import nltk.collocations\n",
    "from nltk import BigramCollocationFinder\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2218577f-caad-488a-9a8d-2bae61bc067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words.add(':')\n",
    "stop_words.add(',')\n",
    "stop_words.add('.')\n",
    "stop_words.add(', ')\n",
    "stop_words.add('. ')\n",
    "stop_words.add('*')\n",
    "stop_words.add(\"'\")\n",
    "stop_words.add(\"'s\")\n",
    "stop_words.add('e.g')\n",
    "stop_words.add('employees')\n",
    "stop_words.add('applicants')\n",
    "stop_words.add(')')\n",
    "stop_words.add('(')\n",
    "stop_words.add('eligible')\n",
    "stop_words.add('participate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b7a1243-d988-43a9-9b07-e833627cae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_n_grams(word_list, n, top_n):\n",
    "    '''\n",
    "        Function to return ngrams\n",
    "        word_list: pass lowercase word list (filtered for stop words)\n",
    "        n: the number of words in each phrase (gram)\n",
    "        top_n: top n number of matches \n",
    "    '''\n",
    "    grams = list(ngrams(word_list, n))\n",
    "    freq_dist = FreqDist(grams)\n",
    "    \n",
    "    topn = freq_dist.most_common(top_n)\n",
    "    return(topn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52aa6f16-3c8d-463e-b123-9bd4b439b102",
   "metadata": {},
   "outputs": [],
   "source": [
    "## In this cell I'm going to add the list of common tokens to the dataframe\n",
    "\n",
    "bigram_list = []\n",
    "trigram_list = []\n",
    "\n",
    "#Create a dictionary of the most common bigrams\n",
    "bigram_dict = {}\n",
    "trigram_dict = {}\n",
    "\n",
    "#for every job in job_list dataframe\n",
    "for i in range(len(jobs_df)): # change to len(jobs_df)\n",
    "    # print(jobs_df['job_description'][i], '\\n')\n",
    "    # Grab the job description\n",
    "    text = jobs_df['job_description'][i]\n",
    "\n",
    "    #Tokenize and filter unnecessary words, and put relevant words i\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_list = []\n",
    "    for word in tokens:\n",
    "        if word.casefold() not in stop_words:\n",
    "            filtered_list.append(word.lower())  \n",
    "    \n",
    "    # For bigrams\n",
    "    # add bigrams\n",
    "    top8 = get_n_grams(filtered_list, 2, 8)\n",
    "    bigram_list.append(top8)\n",
    "    for tup in top8:\n",
    "        if tup[0] not in bigram_dict:\n",
    "            bigram_dict[tup[0]] = tup[1]\n",
    "        else:\n",
    "            bigram_dict[tup[0]] += tup[1]\n",
    "\n",
    "    # add trigrams\n",
    "    top5 = get_n_grams(filtered_list, 3, 2)\n",
    "    bigram_list.append(top5)\n",
    "    for tup in top5:\n",
    "        if tup[0] not in bigram_dict:\n",
    "            trigram_dict[tup[0]] = tup[1]\n",
    "        else:\n",
    "            trigram_dict[tup[0]] += tup[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02640fc2-5a79-4ae8-88f7-51d1aebdaf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_bigram = (sorted(bigram_dict.items(), key=lambda item: item[1],  reverse=True))\n",
    "sorted_trigram = (sorted(trigram_dict.items(), key=lambda item: item[1],  reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dc7403-100c-4f79-b1d5-34ae225b59de",
   "metadata": {},
   "source": [
    "## Analyzing Job Description common phrases\n",
    "\n",
    "Below we can see the top 100 bigrams that are present in job descriptions for \"Data Scientist\" in \"San Francisco Bay Area\".\n",
    "\n",
    "We can immediately draw some insights based on the results\n",
    "* **Companies are emphasizing skills in emerging technologies. This is esepcially applicable to cloud based technologies and skills involving maximizing efficiency in the cloud**\n",
    "    * Skills including Machine Learning, ML models, gen AI use, digital experiences, AI applications, efficient and scalable, and extrapolating data insights are all in high demand.\n",
    " * **There is also a heavy focus on entrepreneurial drive and technology driven innovation.**\n",
    "    * Buzz phrases including shaping the world, shaping the future, billions of people, and mission to inspire are sprinkled in lol.\n",
    "* **Companies are looking for candidates with well rounded experiences, including technical skills in data science and product management, as well as soft skills around working with diverse teams.**\n",
    "    * Phrases such as products build, cross-functional teams, customer service, product development, product engineering, and learning products.\n",
    "* **Finally, in the age of AI and automating, I was surprised and delighted to see that many listings look for creativity and imagination.**\n",
    "    * Companies surprisingly seek out applicants who relate to the following phrases: bring creativity, bring joy, inclusive and diverse, emerging artists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb81e55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('machine', 'learning'), 1010),\n",
      " (('data', 'science'), 312),\n",
      " (('team', 'members'), 150),\n",
      " (('data', 'scientist'), 137),\n",
      " (('equal', 'opportunity'), 95),\n",
      " (('around', 'world'), 94),\n",
      " (('shape', 'future'), 88),\n",
      " (('products', 'build'), 88),\n",
      " (('digital', 'experiences'), 86),\n",
      " (('ml', 'models'), 83),\n",
      " (('data', 'sets'), 76),\n",
      " (('billions', 'people'), 74),\n",
      " (('people', 'hundreds'), 74),\n",
      " (('hundreds', 'millions'), 74),\n",
      " (('learning', 'models'), 66),\n",
      " (('deep', 'learning'), 66),\n",
      " (('wide', 'array'), 64),\n",
      " (('years', 'experience'), 61),\n",
      " (('learning', 'algorithms'), 53),\n",
      " (('cross-functional', 'teams'), 53),\n",
      " (('tecton', '’'), 52),\n",
      " (('use', 'cases'), 52),\n",
      " (('generative', 'ai'), 52),\n",
      " (('inspire', 'creativity'), 51),\n",
      " (('creativity', 'bring'), 51),\n",
      " (('bring', 'joy'), 51),\n",
      " (('los', 'angeles'), 51),\n",
      " (('adobe', '’'), 51),\n",
      " (('data', 'analysis'), 49),\n",
      " (('data', 'scientists'), 49),\n",
      " (('paid', 'time'), 48),\n",
      " (('help', 'us'), 43),\n",
      " (('skills', 'experience'), 42),\n",
      " (('’', 'genai'), 39),\n",
      " (('genai', 'use'), 39),\n",
      " (('world', 'digital'), 37),\n",
      " (('experiences', 'adobe'), 37),\n",
      " (('’', 'give'), 37),\n",
      " (('years', 'relevant'), 36),\n",
      " (('ai', 'research'), 36),\n",
      " (('mission', 'inspire'), 34),\n",
      " (('inclusive', 'diverse'), 34),\n",
      " (('product', 'strategy'), 33),\n",
      " (('learning', 'engineer'), 32),\n",
      " (('model', 'training'), 31),\n",
      " (('product', 'development'), 30),\n",
      " (('believe', 'ml'), 30),\n",
      " (('strong', 'technical'), 30),\n",
      " (('linkedin', '’'), 30),\n",
      " (('samsung', 'ads'), 30),\n",
      " (('give', 'everyone—from'), 30),\n",
      " (('everyone—from', 'emerging'), 30),\n",
      " (('emerging', 'artists'), 30),\n",
      " (('computer', 'science'), 30),\n",
      " (('team', 'owns'), 29),\n",
      " (('ai', 'applications'), 28),\n",
      " (('including', 'limited'), 27),\n",
      " (('san', 'francisco'), 26),\n",
      " (('opportunity', 'employer'), 26),\n",
      " (('new', 'york'), 26),\n",
      " (('customers', '’'), 26),\n",
      " (('product', 'engineering'), 24),\n",
      " (('salary', 'range'), 24),\n",
      " (('high', 'velocity'), 24),\n",
      " (('use', 'data'), 24),\n",
      " (('pricing', 'team'), 24),\n",
      " (('distributed', 'training'), 24),\n",
      " (('best', 'practices'), 22),\n",
      " (('hands', 'experience'), 22),\n",
      " (('scientist', '/ml'), 22),\n",
      " (('/ml', 'engineer'), 22),\n",
      " (('subject', 'matter'), 22),\n",
      " (('matter', 'experts'), 22),\n",
      " (('work', 'experience'), 22),\n",
      " (('linkedin', 'committed'), 21),\n",
      " (('decision', 'making'), 21),\n",
      " (('drive', 'member'), 20),\n",
      " (('staff', 'data'), 20),\n",
      " (('business', 'problems'), 20),\n",
      " (('job', 'market'), 20),\n",
      " (('customer', 'service'), 20),\n",
      " (('rapidly', 'changing'), 20),\n",
      " (('supply', '/'), 20),\n",
      " (('/', 'demand'), 20),\n",
      " (('--', '--'), 19),\n",
      " (('working', 'large'), 18),\n",
      " (('range', 'role'), 18),\n",
      " (('compensation', 'decisions'), 18),\n",
      " (('tiktok', 'mission'), 18),\n",
      " (('data', 'insights'), 18),\n",
      " (('achieve', 'financial'), 18),\n",
      " (('efficient', 'scalable'), 18),\n",
      " (('statistical', 'modeling'), 18),\n",
      " (('learning', 'products'), 18),\n",
      " (('santa', 'clara'), 18),\n",
      " (('clara', 'ca'), 18),\n",
      " (('degree', 'computer'), 18),\n",
      " (('since', '2010'), 18),\n",
      " (('team', 'help'), 17),\n",
      " (('team', 'building'), 16)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(sorted_bigram[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61cc27-0b3a-4923-877c-1169729c23ef",
   "metadata": {},
   "source": [
    "## In the next session, I want to focus on training a model that categorizes the phrases based on the category in which they belong. I anticipate categories including:\n",
    "* Technical data science skills\n",
    "* Technical app development skills\n",
    "* AI focused skills\n",
    "* Working with Teams\n",
    "* Employment terms\n",
    "\n",
    "and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00f5252-a1b5-40c5-9530-cea698fe2520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
